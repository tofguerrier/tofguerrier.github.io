<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Tweets word-cloud – Part 2</title>
  <meta name="description" content="As in part 1, we load the data and the required packages.tw &lt;- read.csv(file = tweets,header = TRUE)require(tm)require(wordcloud)We can as previously crea...">

  <link rel="icon" href="/img/favicon.ico">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://tofguerrier.github.io/2014/07/22/tweets-word-cloud-part-2.html">
  <link rel="alternate" type="application/rss+xml" title="Christophe website" href="https://tofguerrier.github.io/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Christophe website</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
          <a class="page-link" href="/blog.html">Blog</a>
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="/now.html">Now</a>
          
        
          
        
          
          <a class="page-link" href="/links/">Links</a>
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Tweets word-cloud – Part 2</h1>
    <p class="post-meta"><time datetime="2014-07-22T22:56:00+01:00" itemprop="datePublished">Jul 22, 2014</time> • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Christophe Guerrier</span></span></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    As in <a href="http://tofstatistics.wordpress.com/2014/07/17/tweets-word-cloud-part-1/" title="Previous post">part 1</a>, we load the data and the required packages.<br /><br /><pre class="r"><div style="text-align: justify;"><br /><b>tw &lt;- read.csv(file = tweets,header = TRUE)</b></div><br /><b><br /></b><code><div style="text-align: justify;"><br /><b>require(tm)</b></div><br /><b><br /></b><div style="text-align: justify;"><br /><b>require(wordcloud)</b></div><br /></code></pre><br /><br />We can as previously create a corpus. In the package <strong>tm</strong>, the main data structure is an object collecting text documents.<br />More detail can be found there:&nbsp;<a href="http://cran.r-project.org/web/packages/tm/vignettes/tm.pdf" title="CRAN R tm package">http://cran.r-project.org/web/packages/tm/vignettes/tm.pdf</a><br /><br />I don't quite understand why, but you cannot directly input a data frame, but use a Source object - here via the appropriate command.&nbsp;That last command (<em>DataframeSource</em>) takes a data frame on convert it into the appropriate object format.<br /><br />Initially I tried to put <strong>tw$text</strong> directly, but this return a list not a data frame, hence the necessary coercion.<br /><br /><pre class="r"><code><br /><b>tw.corpus &lt;- Corpus(DataframeSource(as.data.frame(tw$text)))</b></code></pre><br /><br />Once the text are formatted in the right data structure for the package, we can avail the function of the tm package.<br /><br />The most useful here for us, is <em><b>tm_map</b></em>, seen previously, I first remove the punctuation symbols with it, but a side effect is that all the users twitter handle lost their <strong>@</strong> symbols. Here I want to remove the user handle all together.<br /><br />My first idea was to use <em><b>tm_map</b></em> and <em><b>removewords</b></em>, meaning i had to create ( or detect ) a list of all twitter user handle.<br /><br /><pre class="r"><code><b>tm_map(tw.corpus, <br />  function(x) removeWords(x, grep("@[\\w\\d_]+", x=strsplit(x, split=" "), value = TRUE)))</b></code></pre><br />But it seems way too complicated, and needed to deal with many exceptions around punctuation. So that not might be the best approach.<br />At that stage I decided to change my strategy. I should the processing before creating the corpus.<br /><br />Clean up time, and reload.<br /><br /><pre class="r"><code><b>rm(list=ls())<br />tw =&nbsp;read.csv(file = tweets,header = TRUE)</b></code></pre><br />At that stage <em>tw$text</em> is a list of string. I am going to merge those, remove the user handle ( actually store them in a separate list). Put all separate words into a long list<br /><br /><pre class="r"><code><b>tw.txt = unlist(tw$text)<br />tw.words = unlist(strsplit(as.character(tw.txt), split=" "))</b></code></pre><br />Extract user handles, using perl type regular expression since I am more familiar with those.<br /><pre class="r"><code>tw.usrhandle = grep("@[\\w]+", tw.words, perl = TRUE, value = TRUE) </code></pre><br />A bit of cleanup is necessary removing extra punctuation, again the first line would remove the @, which i want to keep, after examining the handle, there is actually only 2 symbols to remove, this is done in the second line.<br /><br /><pre class="r"><code><b>#tw.usrhandle_1 = gsub("[[:punct:]]", "", tw.usrhandle)<br />tw.usrhandle = gsub("[\\:\\)]", "", tw.usrhandle)</b></code></pre><br />We can build an barplot from that, to see the frequency of handle cited in the tweets.<br /><pre class="r"><code>barplot(table(tw.usrhandle))</code></pre><br />For better looking, let's move to <em>ggplot2</em>:<br /><br /><pre class="r"><code><b>require(ggplot2)<br />#Create a data frame for easier use<br />tw.usr.df = as.data.frame(table(tw.usrhandle))</b></code></pre><br /><br /><b>ggplot(data = tw.usr.df, aes(x=tw.usrhandle, y=Freq, order=Freq)) +</b><br /><b>&nbsp; geom_bar(colour="black", fill="#DD8888", width=.7, stat="identity") +</b><br /><b>&nbsp; theme(axis.title.x = element_text(face="bold", colour="#990000", size=20),</b><br /><b>&nbsp; axis.text.x = element_text(angle=90, vjust=0.5, size=10))</b><br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://tofstatistics.files.wordpress.com/2014/07/usr_hist.png" style="margin-left: auto; margin-right: auto;"><img alt="barplot frequency of user handle found in the tweets." class="wp-image-28 size-large" height="445" src="https://tofstatistics.files.wordpress.com/2014/07/usr_hist.png?w=660" title="barplot frequency of user handle found in the tweets." width="660" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><span style="font-size: small; text-align: start;">Barplot: Frequency of user handle found in the tweets.</span></td></tr></tbody></table><br />We can have a look at how many, user have been cited in the tweets, here 859.<br /><pre class="r"><code><br /><b>length(unique(tw.usrhandle))</b></code></pre><br />Re-ordering, by frequency, before plotting<br /><pre class="r"><code><br /><b>tw.usr.df = transform(tw.usr.df, tw.usrhandle = reorder(tw.usrhandle, Freq))</b></code></pre><br />Or in a word cloud:<br /><br /><pre class="r"><code><b>wordcloud(words = tw.usr.df$tw.usrhandle, <br />          freq = tw.usr.df$Freq, colors=terrain.colors(20),<br />          min.freq = 10, max.words = Inf, random.order = TRUE)</b></code></pre><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://tofstatistics.files.wordpress.com/2014/07/usr0.png" style="margin-left: auto; margin-right: auto;"><img alt="User handle found in the tweets" class="wp-image-29 size-large" height="428" src="https://tofstatistics.files.wordpress.com/2014/07/usr0.png?w=660" title="User handle found in the tweets" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><span style="font-size: small; text-align: start;">User handle found in the tweets</span></td></tr></tbody></table><br /><br />We can do the same with hashtag, but in this case let everything down to lower case.<br /><br /><pre class="r"><code><b>tw.tag = grep("#[\\w]+", tw.words, perl=TRUE, value = TRUE)<br />tw.tag = tolower(tw.tag)<br />tw.tag.df = as.data.frame(table(tw.tag))</b><br /><br /><b>par(bg="black")<br /> wordcloud(words = tw.tag.df$tw.tag, freq = tw.tag.df$Freq, colors=c("white","green","orange"),<br /> min.freq = 10, max.words = Inf, random.order = TRUE)<br /> par(bg="white")</b></code></pre><br /><br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://tofstatistics.files.wordpress.com/2014/07/hash.png" style="margin-left: auto; margin-right: auto;"><img alt="hash tag used" class="wp-image-31 size-large" height="431" src="https://tofstatistics.files.wordpress.com/2014/07/hash.png?w=660" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Hashtags used.</td></tr></tbody></table><br />I used 1887 tags so far, which can be found with the first line of code, we can also plot an barplot of the frequency.<br /><br /><pre class="r"><code><b>length(unique(tw.tag))<br />ggplot(data = tw.tag.df, aes(x=tw.tag, y=Freq, order=Freq)) + <br />  geom_bar(colour="black", fill="#DD8888", width=.7, stat="identity") +<br />  theme(axis.title.x = element_text(face="bold", colour="#990000", size=20),axis.text.x  = element_text(angle=90, vjust=0.5, size=10))</b></code></pre><br /><br />Let's go back to the words used<br /><pre class="r"><code>  <b>tw.words.wo.usr = tw.words<br /></b></code></pre><pre class="r"><code>Remove all usr handle<b><br />  tw.words.wo.usr[which(tw.words.wo.usr %in% tw.usrhandle)] = ""<br /></b></code></pre><pre class="r"><code>Remove all hashtags<b> <br />  tw.words.wo.usr[which(tw.words.wo.usr %in% tw.tag)] = ""</b></code></pre><br /><br /><pre class="r"><code><br />barplot frequency of user handle found in the tweets.</code></pre><br /><br /><pre class="r"><code><br /><b>par(bg="black")<br />wordcloud(words = tw.words.wo.usr.df$tw.words.wo.usr, freq = tw.words.wo.usr.df$Freq, colors=c("white","green","orange"),<br />min.freq = 10, max.words = Inf, random.order = TRUE)<br />par(bg="white")</b></code></pre><br /><br /><br />But this generate a word cloud where we can see loads of english stopword like "the", "a" ... etc<br /><br />This is where <em><b>tm</b></em> makes life easier. So time to go back to a corpus and the <em>tm</em> package.<br />Now we have a vector as input, so we use a different construct<br /><pre class="r"><code><br /><b>tw.corpus = Corpus(VectorSource(tw.words.wo.usr))</b></code></pre><br />Here is can basically reuse the same code from last, I wrap it around a function, to make it easier to use in the future - should have done that in part 1 really.<br /><br /><pre class="r"><code><b>process_corpus = function(tw.corpus){<br /> tw.corpus = tm_map(tw.corpus, removePunctuation)<br /> tw.corpus = tm_map(tw.corpus, tolower)<br /> tw.corpus = tm_map(tw.corpus, function(x) removeWords(x, stopwords("english")))<br /> tdm = TermDocumentMatrix(tw.corpus)<br /> m = as.matrix(tdm)<br /> v = sort(rowSums(m),decreasing=TRUE)<br /> d = data.frame(word = names(v),freq=v)<br /> return(d)<br />}</b></code></pre><br /><br /><br />And run the function<br /><pre class="r"><code><br /><b>d = process_corpus(tw.corpus)</b></code></pre><br />Finally plotting the wordcloud<br /><pre class="r"><code><br /><b>wordcloud(words = d$word,freq = d$freq,<br /> scale=c(8,.3),<br /> min.freq=10,<br /> max.words=Inf, random.order=T, rot.per=.15, <br /> vfont=c("sans serif","plain"))</b></code></pre><br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://tofstatistics.files.wordpress.com/2014/07/wordcloud2.png" style="margin-left: auto; margin-right: auto;"><img alt="Word cloud without user handle" class="wp-image-32 size-full" height="432" src="https://tofstatistics.files.wordpress.com/2014/07/wordcloud2.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><span style="font-size: small; text-align: start;">Word cloud without user handle.</span></td></tr></tbody></table><br />In summary, few lessons:<br /><ul><br /><li>it's worth to spend some time to process the data, to put it in a form usable. It can be a tedious process, but once you have the data in the right format, the function and package available in R makes your life really easy.</li><br /><li>Write functions as much as you can, and as early as possible, instead of writing or copying te same lines of code over and over.</li><br /><li>So I have produced nice graphs ( well I think so), but i haven't told any story, so it's a bit pointless.</li></ul><br />A couple of links which were very useful in writing the R code:<br /><ul><br /><li><a href="https://sites.google.com/site/miningtwitter/questions/talking-about/given-users" target="_blank" title="Mining twitter with R">Mining twitter with R</a>.</li><br /><li><a href="https://sites.google.com/site/miningtwitter/basics/text-mining" target="_blank" title="Text mining with R">Text mining with tm</a>.</li></ul>
  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Christophe website</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Christophe website</li>
        <!--  <li><a href="mailto:guerrier.christophe@gmail.com">guerrier.christophe@gmail.com</a></li>  -->
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/tofguerrier"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">tofguerrier</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/tofGuerrier"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">tofGuerrier</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>This site contains some information about me, and a blog on data analysis and other random thoughts. All this is generated with Jekyll ; the blog has been initially migrated from wordpress and blogspot.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>

---
layout: post
title: Boston Housing price and Tobit model
date: '2015-07-05T05:28:00.001-07:00'
author: Christophe Guerrier
tags:
- R
- Statistics
modified_time: '2015-07-05T05:28:43.670-07:00'
blogger_id: tag:blogger.com,1999:blog-1855907497000327522.post-2081646367862775107
blogger_orig_url: http://tofstatistics.blogspot.com/2015/07/boston-housing-price-and-tobit-model.html
---

During my year as a student in UCD, one of my project was to model House Price based on a data set found in: &nbsp;<br /><i><u>Introductory econometrics: A modern approach.&nbsp;J. Wooldridge (2012).</u></i><br /><br />Turns out the data set is actually freely available in the Machine Learning repository:&nbsp;<a href="http://archive.ics.uci.edu/ml/datasets/Housing">http://archive.ics.uci.edu/ml/datasets/Housing</a><br /><br />I am going in this post to revisit the model, I did with my partner during that assignment.<br /><br /><br /><a name='more'></a><br /><br /><h1>Introduction</h1>The dataset is used to illustrate the influence of different factors on house pricing. This is dealt as a linear regression problem, where we want to model the housing price based on a set of explanatory variables. We will first discuss the origin of the data set and some of its peculiarities. We then proceed to the simplest linear regression model. Then we introduce a couple of tweaks to our initial model in order to improve it, and take into account the particularities of some of the variables. Finally we proceed to a validation of our model, before presenting our conclusion.<br /><div class="page" title="Page 1"><div class="layoutArea"><div class="column"><br /></div><br /></div><br /></div><br /><h1>Data: Boston House Pricing</h1><br /><h2>Origin of the data</h2><br /><div class="page" title="Page 1"><br /><div class="layoutArea"><br /><div class="column"><br />The data contains the housing price in 506 communities in the Boston Area, in 1970. It is used in (Wooldridge, 2012, pp. 108, 131, 186-187, 192-194), as an example for regression analysis.<br /><br />The original data origin is coming from a 1978 article: Harrison Jr &amp; Rubin- feld (1978) examining the willingness to pay for clean air, based on house price - actually homeowner price estimates.<br /><br />In Harrison Jr &amp; Rubinfeld (1978), the data was aggregated from di↵erent sources, in particular the 1970 census in the Boston area for the house pricing. The data set contains 506 observations - i.e. 506 communities in the Boston area since we have 1 observation per census tract (Boston Standard Metropoli- tan Statistical Area, 1970). In the original article there was 14 non-constant independent variable, in our case we will be dealing only 8 variables - as given to us. Compare to the original data, the following variables have been removed:&nbsp;black population proportion, proportion of structures built before 1940, pro- portion of area zoned with large lots, proportion of non-retail business area, location contiguous to the Charles River.<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 2"><br /><div class="layoutArea"><br /><div class="column"><br /><h2>House Price</h2><br />Figure 2.1: US Census house price estimation form<br /><br />How house prices were computed from census data. In the census tracts ( see Figure: 2.1 ), homeowner were asked to estimate the selling price of their habitation by ticking one of the 11 price range brackets. The median of those records was then taken to give the estimated price in the data set.Also all tracts with a median value equal to or greater than $50,000 appeared as $50,001. As a result the estimated price is right-censored.<br /><br /><h2>Other peculiarities</h2><br />Additionally to the censoring of price we also notice that the variable rad has some kind of censoring. This can be observed in the histograms: 2.2 . This variable along with the weighted distance to employment centres dist was extracted from MIT Boston study, a↵ecting an index<br /><br /><br /><br /><br /><br /><div class="page" title="Page 1"><br /><div class="layoutArea"><br /><div class="column"><br />2.2 Variables<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 2"><br /><div class="layoutArea"><br /><div class="column"><br />The variables in our data sets are: • Dependent variable<br /><br />– price median housing price, $ • Explanatory variables<br /><br />– crime crimes committed per capita<br />– nox nitrous oxide, parts per 100 million<br /><br />2<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 3"><br /><div class="layoutArea"><br /><div class="column"><br />Figure 2.2: Histograms of explanatory variables<br /><br />– rooms average number of rooms per house<br />– dist weighted distance to 5 employment centers – radial accessibility index to radial highways<br />– proptax property tax per $1000<br />– stratio average student-teacher ratio<br /><br />See Figure 2.2 for a distribution of the explanatory variables.<br /><br />Additionally 3 variables in the data sets also included their log transforma-<br />tion, so we also were reading in from the original file: log(price), log(box), log(proptax).<br /><br />3<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 4"><br /><div class="layoutArea"><br /><div class="column"><br />Figure 2.3: All Figure 2.4: Without Radial Ouliers<br /><br />2.3 Correlation<br /><br />Intuitively we would expect some of those variables to be correlated, for example rad and dist, since you might expect that the closer you are from highways, the closer you would be from the employment centres. We will examine correlation in later section. Also the original article suspected the accessibility variables to be correlated with the pollution (box ).<br /><br />When we computed the correlation matrix ( see Level Plot: 2.3 ), the variables rad and prop tax seems highly correlated ( 0.9102282 ), however the correlation can be explained by the outliers ( see Plot: 2.5. When we removed the outliers, the correlation between those 2 variables falls to: 0.1882562. And the level plot ( see Level Plot: 2.4 ), reveals only a high correlation between price and rooms, which indicates that rooms is an important explanatory variable ( Cor(price, rooms) = 0.89052 when rad=24 removed ).<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />4<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 5"><br /><div class="layoutArea"><br /><div class="column"><br />Figure 2.5: Proptax vs Radial<br /><br />3 Modelisation<br /><br />On our first approach we are fitting simple linear regression, including all (non log transformed) variables.<br /><br />Using simple lm.<br />price = ↵0 + ↵1crime + ↵2nox + ↵3rooms + ↵4dist<br /><br />+↵5radial + ↵6proptax + ↵6stratio + ↵7lowstat log(price) = 0 + 1crime + 2log(nox) + 3rooms + 4dist<br /><br />+5radial + 6log(proptax) + 6stratio + 7lowstat<br /><br />5<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 6"><br /><div class="layoutArea"><br /><div class="column"><br />⌥3.1 Simple Regression<br /><br />lm( price ̃<br />⌃ crime+nox+rooms+dist+radial+proptax+stratio+<br /><br /></div><br /><div class="column"><br />⇧<br /><br />Pr(&gt;|t|) 2.0684e-15 3.2411e-04 5.5431e-07 1.1996e-20 9.3128e-13 1.0824e-05 3.9976e-04 3.0971e-17 5.3517e-25<br /><br />0.7108<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />(Intercept) crime nox rooms dist radial proptax stratio lowstat<br /><br /></div><br /><div class="column"><br />lowstat )<br /><br />Estimate 41533.9909 -122.5444 -1853.2269 4062.6580 -1231.3879 293.1667 -122.3608 -1102.6969 -519.6365 Multiple R-squared:<br /><br /></div><br /><div class="column"><br />Std. Error 5065.2377 33.8467 365.3199 416.9391 167.9645 65.9470 34.3277 125.8861 47.6211 0.7154<br /><br /></div><br /><div class="column"><br />t value 8.20 -3.62 -5.07 9.74 -7.33 4.45 -3.56 -8.76 -10.91 Adjusted R-squared:<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />3.1.1 Logarithm Variables<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />Table 3.1: Simple linear regression<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />⌥We then move to replace the 3 variables: price, box and proptax by their loga- rithms, and fit a simple regression.<br /><br />lm( lprice ̃<br />⌃ crime+lnox+rooms+dist+radial+lproptax+stratio+ ⇧<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />(Intercept) crime lnox rooms dist radial lproptax stratio lowstat<br /><br />We have<br /><br /></div><br /><div class="column"><br />lowstat )<br /><br />Estimate 12.6516 -0.0113 -0.4503 0.0990 -0.0488 0.0115 -0.2274 -0.0404 -0.0283 Multiple R-squared:<br /><br /></div><br /><div class="column"><br />Std. Error 0.3473 0.0014 0.0920 0.0168 0.0073 0.0023 0.0477 0.0050 0.0019 0.7677<br /><br /></div><br /><div class="column"><br />t value 36.43 -8.28 -4.89 5.90 -6.69 5.03 -4.76 -8.13 -14.76 Adjusted R-squared:<br /><br />regression variables.<br /><br /></div><br /><div class="column"><br />Pr(&gt;|t|) 1.9904e-142 1.1864e-15 1.3393e-06 6.7007e-09 5.8819e-11 6.9418e-07 2.5015e-06 3.3826e-15 3.8905e-41 0.764<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />Table 3.2: Simple log linear an improvement on R2 by using log<br /><br />6<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 7"><br /><div class="layoutArea"><br /><div class="column"><br />3.1.2 Wooldridge Model<br /><br />(Wooldridge, 2012, p 153,p216) proposed the two following models: Wooldridge 1:<br /><br />log(price) ⇠ 11.08 0.954log(nox) .134log(dist) + .255rooms .052stratio n = 506,R2 = .581<br /><br />Wooldridge 2:<br />log(price) ⇠ 13.39.902log(nox).087log(dist).545rooms+.062rooms2.048stratio<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />Estimate (Intercept) 11.0839 lnox -0.9535 rooms 0.2545 ldist -0.1343 stratio -0.0525 Multiple R-squared:<br /><br /></div><br /><div class="column"><br />Std. Error 0.3181 0.1167 0.0185 0.0431 0.0059 0.584<br /><br /></div><br /><div class="column"><br />t value 34.84 -8.17 13.74 -3.12 -8.89 Adjusted R-squared:<br /><br /></div><br /><div class="column"><br />Pr(&gt;|t|) 5.6466e-136 2.5713e-15 1.1503e-36 1.9338e-03 1.0692e-17 0.5807<br /><br />Pr(&gt;|t|) 1.8845e-83 2.3406e-14 4.5491e-02 1.0554e-03 1.5567e-06 3.4232e-15<br /><br />0.5988<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />n = 506,R2 = .603<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />Table 3.3: Wooldridge 1<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />(Intercept) lnox ldist rooms I(rooms^2) stratio<br /><br /></div><br /><div class="column"><br />Estimate 13.3855 -0.9017 -0.0868 -0.5451 0.0623 -0.0476 Multiple R-squared<br /><br /></div><br /><div class="column"><br />Std. Error 0.5665 0.1147 0.0433 0.1655 0.0128 0.0059 0.6028<br /><br /></div><br /><div class="column"><br />t value 23.63 -7.86 -2.01 -3.29 4.86 -8.13 Adjusted R-squared:<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />Table 3.4: Wooldridge 2<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />We were able to reproduce their results, see Table: 3.3 on page 7 and Table: 3.4 on page 7.<br /><br />Notice that ’Wooldridge (2012), introduces a new log explanatory variable logdist and a polynomial model on rooms. Since our R-squared was higher, we decided to stick to our log model including 8 variables. comment abou overfitting<br /><br />4 Improving the model 4.1 Indicator variable<br /><br />We observe a gap in the radial observations, with the outstanding value 24. We’re not sure what the value 24 mean, if it’s an out of range or wrong value,<br /><br />7<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 8"><br /><div class="layoutArea"><br /><div class="column"><br />Figure 3.1: Simple Log Regression Figure 3.2: Wooldridge<br />it implies the variable is biased. In order to deal with the possible bias of the<br /><br />variable radial, we introduce a dummy variable ( also know as an indicator ). • Ri = Ri⇤ if observed<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />• Ri = 24 if unobserved if unobserved<br /><br /></div><br /><div class="column"><br />Ind = 1unobserved<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />We then create two additional variables based on the indicator: Rad2 = Radial ⇥ (1 Ind)<br /><br />crime + lnox + lproptax2 )<br /><br />Model with indicator variables<br /><br />Multiple R-squared: 0.7676, Adjusted R-squared: 0.7634<br /><br />8<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />lproptax2 = lproptax ⇥ (1 Ind) We fit a new regression (lm) using those variables.<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />⌥lm ( lprice ̃<br />⌃ ind + radial2 + dist + strait + lowstat + rooms + ⇧<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 9"><br /><div class="layoutArea"><br /><div class="column"><br />Figure 4.1: Variable Radial<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />(Intercept) indTRUE radial2 ... lproptax2<br /><br /></div><br /><div class="column"><br />Estimate 12.616 -1.178 0.017<br /><br /></div><br /><div class="column"><br />Std. Error 0.349 0.277 0.007<br /><br /></div><br /><div class="column"><br />t value 36.110 -4.254 2.640<br /><br /></div><br /><div class="column"><br />Pr(&gt;|t|) 6.310E-141 2.513E-05 8.559E-03<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />-0.226<br />Table 4.1: Regression of house prices with Radial2<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />0.048<br /><br /></div><br /><div class="column"><br />-4.744<br /><br /></div><br /><div class="column"><br />2.750E-06<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />4.2 Tobit Model<br /><br />In order to deal with the truncation of the dependent variable price, we intro- duce a tobit model (Tobin (1958)) instead of our standard linear regression . 16 values are exactly 50, 001, which is very strange. The linear model could be<br /><br />9<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 10"><br /><div class="layoutArea"><br /><div class="column"><br />wrong! Price seems to be truncated. Tobit Model We observe:<br /><br />• Yi = Yi⇤ if Yi⇤ &lt; K<br /><br />• Yi = K if Yi⇤ K<br />We want to estimate: Yi⇤ = Xi + "i<br /><br />Method<br /><br />• The likelihood is quite more complicated.<br /><br />• Maximum likelihood by numerical optimization.<br /><br />To deal with a truncated dependent variable There are some packages to do that in R.<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />(Intercept) indTRUE radial2 dist stratio lowstat rooms crime lnox lproptax2 Log(scale)<br /><br /></div><br /><div class="column"><br />Estimate Std. Error 12.603 0.356 -1.173 0.282 0.017 0.007 -0.050 0.007 -0.041 0.005 -0.028 0.002 0.106 0.017 -0.011 0.001 -0.455 0.094 -0.226 0.049 -1.597 0.032<br /><br /></div><br /><div class="column"><br />z value 35.363 -4.155 2.527 -6.785 -8.046 -14.487 6.158 -7.981 -4.857 -4.637 -49.563<br /><br /></div><br /><div class="column"><br />Pr(&gt;|z|) 6.312E-274 3.259E-05 1.149E-02 1.160E-11 8.553E-16 1.469E-47 7.357E-10 1.448E-15 1.190E-06 3.534E-06 0.000E+00<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />Table 4.2: Regression of house prices (Tobit Model)<br /><br />5 Results and Validation<br /><br />To validate our tobit model we use a k-fold cross validation ( k = 10 ). We divided the original data sets into k subsample of roughly equal size. We remove then remove one sample, and ran our tobit regression on the remaining k 1 subsamples. The resulting model was then used to predict the price, with the explanatory variable of the removed subs ample. We then compare the predicted value to original recorded house price. And we repeat the process for each k subsample. The resulting prediction ( see Figure: 5.1 ), seems relatively good. Based on our prediction, there is a possibility that the house price equal<br /><br />10<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 11"><br /><div class="layoutArea"><br /><div class="column"><br />Figure 5.1: Tobit 10 fold predicted vs recorded<br /><br />to $50,001 are actually mis-estimated ( our predictions shows them below the threshold based on the explanatory variables ). A model omitting the ceiling price ( removing the 16 observations which price = $50,001 ), followed by 10 fold validation gives similar results.<br /><br />6 Conclusion<br /><br />Though using a Tobit model is the more statistically grounded way to deal with the censored data, our analysis shows, that in this case, it does not add much information to the simpler regression. Another way to deal with the 16 out standings house price, could be to remove those data points, leaving us with 490 points. Similarly to Gilley &amp; Pace (1996) the qualitative results can still hold with or without adding a tobit model.<br /><br />11<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 12"><br /><div class="layoutArea"><br /><div class="column"><br />Figure 5.2: Tweaked lm 10 fold predicted vs recorded<br /><br />We also identify further possible area of investigations: • heteroscedasticity<br />• removing variables to simplify our model.<br />• use AIC or BIC to compare models.<br /><br />• clustering, Are we dealing with multiple or a single housing market ?<br /><br />12<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 13"><br /><div class="layoutArea"><br /><div class="column"><br />7 Annexe<br />⌥7.1 Rcode simple regression<br /><br />simplefit &lt; lm ( price ̃ crime + nox + rooms + dist + radial + proptax + stratio + lowstat , data=myhousing)<br /><br />summary( simplefit )<br /><br />simplelogfit &lt; lm ( lprice ̃ crime + lnox + rooms + dist + radial + lproptax + stratio + lowstat , data=<br /><br />myhousing ) summary( simplelogfit )<br /><br />#Residual plot<br /><br />plot(y=simplelogfit$residuals ,x=simplelogfit$fitted . values ,xlab=”fitted”,ylab=”residuals”,bty=’n’)<br /><br />myhousing$ldist &lt; log(myhousing$dist )<br />woolfit &lt; lm ( lprice ̃ lnox + rooms + ldist + stratio<br /><br />, data=myhousing ) summary( woolfit )<br /><br />woolfit2 &lt; lm ( lprice ̃ lnox + ldist + rooms + I(rooms ˆ2) + stratio , data=myhousing)<br /><br />summary( woolfit2 )<br />plot(y=woolfit2$residuals ,x=woolfit2$fitted . values , xlab=”<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />f i t t e d ” , y l a b=” r e s i d u a l s ” , b t y= ’ n ’ ) anova( simplelogfit , woolfit2 )<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />⌃⇧<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />13<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 14"><br /><div class="layoutArea"><br /><div class="column"><br />⌥7.2 Rcode tobit regression<br /><br />ind = radial==24<br />radial2 = radial⇤(1 ind) lproptax2 = lproptax⇤(1 ind)<br /><br />modelI &lt; lm ( lprice ̃<br />ind + radial2 + dist + strait + lowstat + rooms +<br /><br />crime + lnox + lproptax2 ) summary( modelI )<br /><br />#Introducing tobit<br />#Upper limit is log (50001)<br /><br />modelT = tobit( lprice ̃<br />ind + radial2 + dist + strait + lowstat + rooms +<br /><br />crime + lnox + lproptax2 , right =10.8198)<br /><br />summary(modelT) ⌃⇧<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />14<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 15"><br /><div class="layoutArea"><br /><div class="column"><br />⌥7.3 Rcode validation<br /><br />library (AER) #Nfold tobit<br /><br />NfoldTobit &lt; function(dataf , Nfolds){<br />plot(dataf$lprice ,dataf$lprice ,type=’n’,xlab=”Log Price<br /><br />recorded”, ylab=”Log predicted price”) abline(a=0,b=1,col=”black”) abline(a=0,b=0.9,col=”black” , lty=3) abline(a=0,b=1.1,col=”black” , lty=3)<br /><br />folds = sample(rep(1:Nfolds ,length=dim(dataf)[1])) errs=0<br />for(i in 1:Nfolds) {<br /><br />dnew = dataf[folds!=i ,]<br />model = tobit ( lprice ̃ind + radial2 +dist+stratio+<br /><br />lowstat+rooms+crime+lnox+lproptax2 , right=10.8198,<br /><br />data=dnew)<br />#new data for prediction<br /><br />pred = predict(model,newdata=dataf[folds==i,]) points(x=dataf[folds==i,]$lprice, y=pred,pch=4,col<br /><br />=”black”)<br />errs = errs + sum((dataf[folds==i ,]$lprice pred)ˆ2)<br /><br />}<br /><br />return( errs ) }<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />⌃⌥ ⇧<br /><br />Nfoldlm = function(dataf ,Nfolds) {<br />plot(dataf$lprice ,dataf$lprice ,type=’n’,xlab=”Log Price<br /><br />recorded”, ylab=”Log predicted price”) abline(a=0,b=1,col=”black”) abline(a=0,b=0.9,col=”black” , lty=3) abline(a=0,b=1.1,col=”black” , lty=3)<br /><br /># abline(a=0,b=0.5,col=”grey”,lty=3) # abline(a=0,b=1.5,col=”grey”,lty=3)<br /><br />folds = sample(rep(1:Nfolds ,length=dim(dataf)[1])) errs=0<br />for(i in 1:Nfolds) {<br /><br />dnew = dataf[folds!=i ,]<br />model = lm( lprice ̃ ind + radial2 + dist + stratio +<br /><br />15<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />NfoldTobit(myhousing ,10)<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 16"><br /><div class="layoutArea"><br /><div class="column"><br />lowstat + rooms +<br />crime + lnox + lproptax , data=dnew)<br /><br />pred = predict(model,newdata=dataf[folds==i,]) points(x=dataf[folds==i,]$lprice, y=pred,pch=4,col<br /><br />=”black”)<br />errs = errs + sum((dataf[folds==i ,]$lprice pred)ˆ2)<br /><br />}<br /><br />return( errs ) }<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />⌃⇧<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />Nfoldlm ( myhousing , 1 0 )<br /><br /></div><br /></div><br /><div class="layoutArea"><br /><div class="column"><br />16<br /><br /></div><br /></div><br /></div><br /><div class="page" title="Page 17"><br /><div class="layoutArea"><br /><div class="column"><br /><br /><br /></div><br /></div><br /></div><br /></div><br /></div><br /></div>
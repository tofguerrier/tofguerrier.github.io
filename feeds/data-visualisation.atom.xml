<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Christophe website - Data Visualisation</title><link href="/" rel="alternate"></link><link href="/feeds/data-visualisation.atom.xml" rel="self"></link><id>/</id><updated>2014-07-22T00:00:00+01:00</updated><entry><title>Tweets word cloud - Part 2</title><link href="/tweets-word-cloud-part-2.html" rel="alternate"></link><published>2014-07-22T00:00:00+01:00</published><updated>2014-07-22T00:00:00+01:00</updated><author><name>Christophe Guerrier</name></author><id>tag:None,2014-07-22:/tweets-word-cloud-part-2.html</id><summary type="html">How to make a word cloud with R.</summary><content type="html">


As in &lt;a href="http://tofstatistics.wordpress.com/2014/07/17/tweets-word-cloud-part-1/" title="Previous post"&gt;part 1&lt;/a&gt;, we load the data and the required packages.&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;b&gt;tw &amp;lt;- read.csv(file = tweets,header = TRUE)&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;code&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;b&gt;require(tm)&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;b&gt;require(wordcloud)&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;We can as previously create a corpus. In the package &lt;strong&gt;tm&lt;/strong&gt;, the main data structure is an object collecting text documents.&lt;br /&gt;More detail can be found there:&amp;nbsp;&lt;a href="http://cran.r-project.org/web/packages/tm/vignettes/tm.pdf" title="CRAN R tm package"&gt;http://cran.r-project.org/web/packages/tm/vignettes/tm.pdf&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;I don't quite understand why, but you cannot directly input a data frame, but use a Source object - here via the appropriate command.&amp;nbsp;That last command (&lt;em&gt;DataframeSource&lt;/em&gt;) takes a data frame on convert it into the appropriate object format.&lt;br /&gt;&lt;br /&gt;Initially I tried to put &lt;strong&gt;tw$text&lt;/strong&gt; directly, but this return a list not a data frame, hence the necessary coercion.&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;br /&gt;&lt;b&gt;tw.corpus &amp;lt;- Corpus(DataframeSource(as.data.frame(tw$text)))&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Once the text are formatted in the right data structure for the package, we can avail the function of the tm package.&lt;br /&gt;&lt;br /&gt;The most useful here for us, is &lt;em&gt;&lt;b&gt;tm_map&lt;/b&gt;&lt;/em&gt;, seen previously, I first remove the punctuation symbols with it, but a side effect is that all the users twitter handle lost their &lt;strong&gt;@&lt;/strong&gt; symbols. Here I want to remove the user handle all together.&lt;br /&gt;&lt;br /&gt;My first idea was to use &lt;em&gt;&lt;b&gt;tm_map&lt;/b&gt;&lt;/em&gt; and &lt;em&gt;&lt;b&gt;removewords&lt;/b&gt;&lt;/em&gt;, meaning i had to create ( or detect ) a list of all twitter user handle.&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;tm_map(tw.corpus, &lt;br /&gt;  function(x) removeWords(x, grep("@[\\w\\d_]+", x=strsplit(x, split=" "), value = TRUE)))&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;But it seems way too complicated, and needed to deal with many exceptions around punctuation. So that not might be the best approach.&lt;br /&gt;At that stage I decided to change my strategy. I should the processing before creating the corpus.&lt;br /&gt;&lt;br /&gt;Clean up time, and reload.&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;rm(list=ls())&lt;br /&gt;tw =&amp;nbsp;read.csv(file = tweets,header = TRUE)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;At that stage &lt;em&gt;tw$text&lt;/em&gt; is a list of string. I am going to merge those, remove the user handle ( actually store them in a separate list). Put all separate words into a long list&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;tw.txt = unlist(tw$text)&lt;br /&gt;tw.words = unlist(strsplit(as.character(tw.txt), split=" "))&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;Extract user handles, using perl type regular expression since I am more familiar with those.&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;tw.usrhandle = grep("@[\\w]+", tw.words, perl = TRUE, value = TRUE) &lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;A bit of cleanup is necessary removing extra punctuation, again the first line would remove the @, which i want to keep, after examining the handle, there is actually only 2 symbols to remove, this is done in the second line.&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;#tw.usrhandle_1 = gsub("[[:punct:]]", "", tw.usrhandle)&lt;br /&gt;tw.usrhandle = gsub("[\\:\\)]", "", tw.usrhandle)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;We can build an barplot from that, to see the frequency of handle cited in the tweets.&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;barplot(table(tw.usrhandle))&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;For better looking, let's move to &lt;em&gt;ggplot2&lt;/em&gt;:&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;require(ggplot2)&lt;br /&gt;#Create a data frame for easier use&lt;br /&gt;tw.usr.df = as.data.frame(table(tw.usrhandle))&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;ggplot(data = tw.usr.df, aes(x=tw.usrhandle, y=Freq, order=Freq)) +&lt;/b&gt;&lt;br /&gt;&lt;b&gt;&amp;nbsp; geom_bar(colour="black", fill="#DD8888", width=.7, stat="identity") +&lt;/b&gt;&lt;br /&gt;&lt;b&gt;&amp;nbsp; theme(axis.title.x = element_text(face="bold", colour="#990000", size=20),&lt;/b&gt;&lt;br /&gt;&lt;b&gt;&amp;nbsp; axis.text.x = element_text(angle=90, vjust=0.5, size=10))&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://tofstatistics.files.wordpress.com/2014/07/usr_hist.png" style="margin-left: auto; margin-right: auto;"&gt;&lt;img alt="barplot frequency of user handle found in the tweets." class="wp-image-28 size-large" height="445" src="https://tofstatistics.files.wordpress.com/2014/07/usr_hist.png?w=660" title="barplot frequency of user handle found in the tweets." width="660" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;&lt;span style="font-size: small; text-align: start;"&gt;Barplot: Frequency of user handle found in the tweets.&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;We can have a look at how many, user have been cited in the tweets, here 859.&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;br /&gt;&lt;b&gt;length(unique(tw.usrhandle))&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;Re-ordering, by frequency, before plotting&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;br /&gt;&lt;b&gt;tw.usr.df = transform(tw.usr.df, tw.usrhandle = reorder(tw.usrhandle, Freq))&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;Or in a word cloud:&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;wordcloud(words = tw.usr.df$tw.usrhandle, &lt;br /&gt;          freq = tw.usr.df$Freq, colors=terrain.colors(20),&lt;br /&gt;          min.freq = 10, max.words = Inf, random.order = TRUE)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://tofstatistics.files.wordpress.com/2014/07/usr0.png" style="margin-left: auto; margin-right: auto;"&gt;&lt;img alt="User handle found in the tweets" class="wp-image-29 size-large" height="428" src="https://tofstatistics.files.wordpress.com/2014/07/usr0.png?w=660" title="User handle found in the tweets" width="640" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;&lt;span style="font-size: small; text-align: start;"&gt;User handle found in the tweets&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;&lt;br /&gt;We can do the same with hashtag, but in this case let everything down to lower case.&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;tw.tag = grep("#[\\w]+", tw.words, perl=TRUE, value = TRUE)&lt;br /&gt;tw.tag = tolower(tw.tag)&lt;br /&gt;tw.tag.df = as.data.frame(table(tw.tag))&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;par(bg="black")&lt;br /&gt; wordcloud(words = tw.tag.df$tw.tag, freq = tw.tag.df$Freq, colors=c("white","green","orange"),&lt;br /&gt; min.freq = 10, max.words = Inf, random.order = TRUE)&lt;br /&gt; par(bg="white")&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://tofstatistics.files.wordpress.com/2014/07/hash.png" style="margin-left: auto; margin-right: auto;"&gt;&lt;img alt="hash tag used" class="wp-image-31 size-large" height="431" src="https://tofstatistics.files.wordpress.com/2014/07/hash.png?w=660" width="640" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Hashtags used.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;I used 1887 tags so far, which can be found with the first line of code, we can also plot an barplot of the frequency.&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;length(unique(tw.tag))&lt;br /&gt;ggplot(data = tw.tag.df, aes(x=tw.tag, y=Freq, order=Freq)) + &lt;br /&gt;  geom_bar(colour="black", fill="#DD8888", width=.7, stat="identity") +&lt;br /&gt;  theme(axis.title.x = element_text(face="bold", colour="#990000", size=20),axis.text.x  = element_text(angle=90, vjust=0.5, size=10))&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Let's go back to the words used&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;  &lt;b&gt;tw.words.wo.usr = tw.words&lt;br /&gt;&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre class="r"&gt;&lt;code&gt;Remove all usr handle&lt;b&gt;&lt;br /&gt;  tw.words.wo.usr[which(tw.words.wo.usr %in% tw.usrhandle)] = ""&lt;br /&gt;&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre class="r"&gt;&lt;code&gt;Remove all hashtags&lt;b&gt; &lt;br /&gt;  tw.words.wo.usr[which(tw.words.wo.usr %in% tw.tag)] = ""&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;br /&gt;barplot frequency of user handle found in the tweets.&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;br /&gt;&lt;b&gt;par(bg="black")&lt;br /&gt;wordcloud(words = tw.words.wo.usr.df$tw.words.wo.usr, freq = tw.words.wo.usr.df$Freq, colors=c("white","green","orange"),&lt;br /&gt;min.freq = 10, max.words = Inf, random.order = TRUE)&lt;br /&gt;par(bg="white")&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;But this generate a word cloud where we can see loads of english stopword like "the", "a" ... etc&lt;br /&gt;&lt;br /&gt;This is where &lt;em&gt;&lt;b&gt;tm&lt;/b&gt;&lt;/em&gt; makes life easier. So time to go back to a corpus and the &lt;em&gt;tm&lt;/em&gt; package.&lt;br /&gt;Now we have a vector as input, so we use a different construct&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;br /&gt;&lt;b&gt;tw.corpus = Corpus(VectorSource(tw.words.wo.usr))&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;Here is can basically reuse the same code from last, I wrap it around a function, to make it easier to use in the future - should have done that in part 1 really.&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;process_corpus = function(tw.corpus){&lt;br /&gt; tw.corpus = tm_map(tw.corpus, removePunctuation)&lt;br /&gt; tw.corpus = tm_map(tw.corpus, tolower)&lt;br /&gt; tw.corpus = tm_map(tw.corpus, function(x) removeWords(x, stopwords("english")))&lt;br /&gt; tdm = TermDocumentMatrix(tw.corpus)&lt;br /&gt; m = as.matrix(tdm)&lt;br /&gt; v = sort(rowSums(m),decreasing=TRUE)&lt;br /&gt; d = data.frame(word = names(v),freq=v)&lt;br /&gt; return(d)&lt;br /&gt;}&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;And run the function&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;br /&gt;&lt;b&gt;d = process_corpus(tw.corpus)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;Finally plotting the wordcloud&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;br /&gt;&lt;b&gt;wordcloud(words = d$word,freq = d$freq,&lt;br /&gt; scale=c(8,.3),&lt;br /&gt; min.freq=10,&lt;br /&gt; max.words=Inf, random.order=T, rot.per=.15, &lt;br /&gt; vfont=c("sans serif","plain"))&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://tofstatistics.files.wordpress.com/2014/07/wordcloud2.png" style="margin-left: auto; margin-right: auto;"&gt;&lt;img alt="Word cloud without user handle" class="wp-image-32 size-full" height="432" src="https://tofstatistics.files.wordpress.com/2014/07/wordcloud2.png" width="640" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;&lt;span style="font-size: small; text-align: start;"&gt;Word cloud without user handle.&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;In summary, few lessons:&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;it's worth to spend some time to process the data, to put it in a form usable. It can be a tedious process, but once you have the data in the right format, the function and package available in R makes your life really easy.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Write functions as much as you can, and as early as possible, instead of writing or copying te same lines of code over and over.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;So I have produced nice graphs ( well I think so), but i haven't told any story, so it's a bit pointless.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;A couple of links which were very useful in writing the R code:&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;&lt;a href="https://sites.google.com/site/miningtwitter/questions/talking-about/given-users" target="_blank" title="Mining twitter with R"&gt;Mining twitter with R&lt;/a&gt;.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;&lt;a href="https://sites.google.com/site/miningtwitter/basics/text-mining" target="_blank" title="Text mining with R"&gt;Text mining with tm&lt;/a&gt;.&lt;/li&gt;&lt;/ul&gt;

</content><category term="Data Visualisation"></category><category term="R"></category><category term="twitter"></category></entry><entry><title>Tweets word-cloud - Part 1</title><link href="/tweets-word-cloud-part-1.html" rel="alternate"></link><published>2014-07-17T00:00:00+01:00</published><updated>2014-07-17T00:00:00+01:00</updated><author><name>Christophe Guerrier</name></author><id>tag:None,2014-07-17:/tweets-word-cloud-part-1.html</id><summary type="html">How to make a word cloud with R.</summary><content type="html">


I have been interesting in looking at my own tweets, and see what kind of visualization and analyze I could run on it. First I used the archive feature on twitter to get a file copy of my tweets, then using the package &lt;a href="http://cran.r-project.org/web/packages/wordcloud/" title="R package wordcloud"&gt;wordcloud&lt;/a&gt;&amp;nbsp;and &lt;a href="http://cran.r-project.org/web/packages/tm/" title="R package tm"&gt;tm&lt;/a&gt;&amp;nbsp;I processed the archive.&lt;br /&gt;&lt;br /&gt;&lt;h1&gt;Getting a&amp;nbsp;twitter snapshot&lt;/h1&gt;&lt;br /&gt;There is way to query your twitter feed directly (using API and package like&lt;a href="http://cran.r-project.org/web/packages/twitteR/index.html" title="R package twitterR"&gt; twitterR&lt;/a&gt;) , but the simplest way I found was to download an &lt;a href="https://blog.twitter.com/2012/your-twitter-archive" title="Getting your twitter archive"&gt;archive&lt;/a&gt;. The process is quite simple, go to your Twitter account settings, there should be a&amp;nbsp;&lt;strong&gt;Request your archive &lt;/strong&gt;link you can click on.&lt;br /&gt;&lt;br /&gt;It will take some time to have your snapshot ready, but when it is, you will receive an email, follow the link and download it. You can can start exploring, by opening the index.html file. The archive is quite neat, you can explore by month and have an overview of your activity over the years.&lt;br /&gt;&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;img alt="archive" class="size-medium wp-image-24" src="http://tofstatistics.files.wordpress.com/2014/07/screen-shot-2014-07-17-at-09-59-36.png?w=300" height="347" style="margin-left: auto; margin-right: auto;" width="640" /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;&lt;span style="font-size: small; text-align: start;"&gt;Screen capture of my twitter archive&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;If you explore the directories unzipped the archive is composed of Json files, there is package to read those, but for my purpose I will use the csv file generated ( called tweets.csv), as I can read that straight away into R.&lt;br /&gt;&lt;br /&gt;&lt;h1&gt;R processing&lt;/h1&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;tweets="filepath/tweets.csv"&lt;br /&gt;tw &amp;lt;- read.csv(file = tweets,header = TRUE)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;Loading the packages I will use&lt;br /&gt; &lt;strong&gt;tm &lt;/strong&gt;is Text Mining Package.A framework for text mining applications within R.&lt;br /&gt; &lt;strong&gt;wordcloud&lt;/strong&gt; allow to generate word cloud pictures.&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;require(tm)&lt;br /&gt;require(wordcloud)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;From the text we create a corpus:&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;tw.corpus &amp;lt;- Corpus(DataframeSource(as.data.frame(tw$text)))&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;Some cleaning up of the world, I will go into more detail in part 2.&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;tw.corpus &amp;lt;- tm_map(tw.corpus, removePunctuation)&lt;br /&gt;tw.corpus &amp;lt;- tm_map(tw.corpus, tolower)&lt;br /&gt;tw.corpus &amp;lt;- tm_map(tw.corpus, function(x) removeWords(x, stopwords("english")))&lt;br /&gt;tdm &amp;lt;- TermDocumentMatrix(tw.corpus)&lt;br /&gt;m &amp;lt;- as.matrix(tdm)&lt;br /&gt;v &amp;lt;- sort(rowSums(m),decreasing=TRUE)&lt;br /&gt;d &amp;lt;- data.frame(word = names(v),freq=v)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;Already we can find the most frequent word, i use:&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;max(d$freq)&lt;br /&gt;d[which.max(d$freq),]$word&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;Which is the word &lt;strong&gt;via&lt;/strong&gt;, used 458 times.&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;dim(d)[1]&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;And find that I used 14619 different words.&lt;br /&gt;&lt;br /&gt;Plotting the word cloud is straightforward from there:&lt;br /&gt;&lt;br /&gt;&lt;pre class="r"&gt;&lt;code&gt;&lt;b&gt;wordcloud(words = d$word,freq = d$freq,&lt;br /&gt;          scale=c(8,.3),&lt;br /&gt;          min.freq=10,&lt;br /&gt;          max.words=dim(d)[1], random.order=T, rot.per=.15, &lt;br /&gt;          vfont=c("sans serif","plain"))&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;And here's the result.&lt;br /&gt;&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;img alt="wordcloud" class="size-medium wp-image-25" src="http://tofstatistics.files.wordpress.com/2014/07/wordcloud1.jpeg?w=300" height="552" style="margin-left: auto; margin-right: auto;" width="640" /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;&lt;span style="font-size: small; text-align: start;"&gt;First word cloud of my past tweets&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;Not too bad for a first pass, but I am unhappy about few things:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;the cloud could use some colours.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;I can see twitter user handle in this, which is not something i want in the final cloud, it probably happen during the removing of the punctuation in the corpus processing. I will need to fix that in part 2. But that also gave the idea to create a cloud with only the user handles to visualize, who i interacted the most with.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;It is very cluttered, I may need to reduce the number of words displayed, or increase the minimum limit. At the moment wordcloud tries to display every word appearing more than 10 times.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;That last command, generates many warning, which need to be investigated.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;See you in Part 2.&lt;br /&gt;&lt;br /&gt;

</content><category term="Data Visualisation"></category><category term="R"></category><category term="twitter"></category></entry></feed>